{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot')\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(28,padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=train_transformations, download=True)\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=test_transformations, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset, valset = train_test_split(trainset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)\n",
    "#valloader = torch.utils.data.DataLoader(valset, batch_size=4, shuffle=False, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_chan, out_channels=out_chan, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_chan)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.dropout(self.drop(x), training=self.training)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, num_class=10):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.net1 = Net(1,16)\n",
    "        self.net2 = Net(16,32)\n",
    "        self.net3 = Net(32,64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.net4 = Net(64,64)\n",
    "        self.net5 = Net(64,64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.net6 = Net(64,128)\n",
    "        self.net7 = Net(128,128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=3)\n",
    "        \n",
    "        self.net = nn.Sequential(self.net1,self.net2,self.net3,self.pool1,self.net4,self.net5,self.pool2,self.net6,self.net7,self.pool3,self.avgpool)\n",
    "        self.fc = nn.Linear(in_features=128,out_features=num_class)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.net(input)\n",
    "        output = output.view(-1,128)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(epoch):\n",
    "    lr = 0.001\n",
    "\n",
    "    if epoch > 50:\n",
    "        lr = lr / 1000000\n",
    "    elif epoch > 40:\n",
    "        lr = lr / 100000\n",
    "    elif epoch > 30:\n",
    "        lr = lr / 10000\n",
    "    elif epoch > 20:\n",
    "        lr = lr / 1000\n",
    "    elif epoch > 10:\n",
    "        lr = lr / 100\n",
    "    elif epoch > 5:\n",
    "        lr = lr / 10\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            images, labels = data\n",
    "            # Clear all accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Predict classes using images from the test set\n",
    "            outputs = model(images)\n",
    "            # Compute the loss based on the predictions and actual labels\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "            # Adjust parameters according to the computed gradients\n",
    "            optimizer.step()\n",
    "            # Update running loss\n",
    "            running_loss += loss.item()\n",
    "            # Print the metrics\n",
    "            if i % 5000 == 4999:\n",
    "                print(\"Epoch {}, Count: {}, Running Loss: {}\".format(epoch+1, i+1,running_loss/5000))\n",
    "        #adjust_learning_rate(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Count: 5000, Running Loss: 6235.261148370802\n",
      "Epoch 1, Count: 10000, Running Loss: 10361.800297427922\n",
      "Epoch 1, Count: 15000, Running Loss: 14024.777436641045\n",
      "Epoch 2, Count: 5000, Running Loss: 3456.4860220146365\n",
      "Epoch 2, Count: 10000, Running Loss: 6771.258725560736\n",
      "Epoch 2, Count: 15000, Running Loss: 9945.807636388461\n",
      "Epoch 3, Count: 5000, Running Loss: 3125.2288926432375\n",
      "Epoch 3, Count: 10000, Running Loss: 6124.01325264154\n",
      "Epoch 3, Count: 15000, Running Loss: 9092.903437818866\n",
      "Epoch 4, Count: 5000, Running Loss: 2838.0045968536288\n",
      "Epoch 4, Count: 10000, Running Loss: 5636.685754989041\n",
      "Epoch 4, Count: 15000, Running Loss: 8477.3511550806\n",
      "Epoch 5, Count: 5000, Running Loss: 2741.8221569583984\n",
      "Epoch 5, Count: 10000, Running Loss: 5451.800809071981\n",
      "Epoch 5, Count: 15000, Running Loss: 8091.801037339144\n"
     ]
    }
   ],
   "source": [
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './fashion-MNIST_e5.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'net = SimpleNet()\\nnet.load_state_dict(torch.load(PATH))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"net = SimpleNet()\n",
    "net.load_state_dict(torch.load(PATH))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data, model_name=model):\n",
    "    model_name.eval()\n",
    "    test_acc = 0.0\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        # Predict classes using images from the test set\n",
    "        outputs = model_name(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        \n",
    "        test_acc += torch.sum(prediction == labels.data)\n",
    "\n",
    "    # Compute the average acc and loss over all 10000 test images\n",
    "    test_acc = round((test_acc / 10000).tolist(), 4)*100\n",
    "\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.66"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for name, param in model.named_parameters():\\n    if param.requires_grad:\\n        print(name, param.data)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top :  0 %\n",
      "Accuracy of Trouser : 90 %\n",
      "Accuracy of Pullover :  2 %\n",
      "Accuracy of Dress : 45 %\n",
      "Accuracy of  Coat : 74 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 29 %\n",
      "Accuracy of Ankle boot : 19 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))\n",
    "with torch.no_grad():\n",
    "    #i=0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \"\"\"if i < 3:\n",
    "            print(outputs)\n",
    "            print(predicted)\n",
    "            i+=1\n",
    "        else:\n",
    "            break\"\"\"\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(num_classes):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        self.fc1 = nn.Linear(in_features= 7 * 7 * 24, out_features=20)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=20, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        #x = self.drop(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        #x = self.drop(x)   \n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 7 * 7 * 24)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  5000] loss: 2.897\n",
      "[1, 10000] loss: 1.883\n",
      "[1, 15000] loss: 1.666\n",
      "[2,  5000] loss: 1.556\n",
      "[2, 10000] loss: 1.461\n",
      "[2, 15000] loss: 1.402\n",
      "[3,  5000] loss: 1.325\n",
      "[3, 10000] loss: 1.265\n",
      "[3, 15000] loss: 1.237\n",
      "[4,  5000] loss: 1.184\n",
      "[4, 10000] loss: 1.160\n",
      "[4, 15000] loss: 1.118\n",
      "[5,  5000] loss: 1.123\n",
      "[5, 10000] loss: 1.074\n",
      "[5, 15000] loss: 1.082\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        img, label = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(img)\n",
    "        \n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5000 == 4999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top : 74 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 77 %\n",
      "Accuracy of Dress : 84 %\n",
      "Accuracy of  Coat : 87 %\n",
      "Accuracy of Sandal : 94 %\n",
      "Accuracy of Shirt : 52 %\n",
      "Accuracy of Sneaker : 94 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 95 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))\n",
    "with torch.no_grad():\n",
    "    #i=0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \"\"\"if i < 3:\n",
    "            print(outputs)\n",
    "            print(predicted)\n",
    "            i+=1\n",
    "        else:\n",
    "            break\"\"\"\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(num_classes):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './fashion-MNIST_NeuNetfirst.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.65"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(testloader,net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py382] *",
   "language": "python",
   "name": "conda-env-py382-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
